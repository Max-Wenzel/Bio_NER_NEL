{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from crf_funcs import *\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.2195953080836135, 'c2': 0.025428990546374215}\n",
      "best CV score: 0.813965433665832\n",
      "model size: 1.00M\n"
     ]
    }
   ],
   "source": [
    "train_sentences = file_opener(\"train\")\n",
    "\n",
    "X_train = [sentence_features(s) for s in train_sentences]\n",
    "y_train = [sentence_labels(s, step_one=True) for s in train_sentences]\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "labels = ['B', 'I']\n",
    "\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = file_opener(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'I']\n",
      "IOB Score: 0.8486726065730688\n"
     ]
    }
   ],
   "source": [
    " X_train = [sentence_features(s) for s in train_sentences]\n",
    "y_train = [sentence_labels(s, step_one=True) for s in train_sentences]\n",
    "\n",
    "X_dev = [sentence_features(s) for s in dev_sentences]\n",
    "y_dev = [sentence_labels(s, step_one=True) for s in dev_sentences]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.2195953080836135,\n",
    "    c2=0.025428990546374215,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "print(labels)\n",
    "y_predicted = crf.predict(X_dev)\n",
    "\n",
    "f1 = metrics.flat_f1_score(y_dev, y_predicted, average='weighted', labels=labels)\n",
    "print(\"IOB Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows a very slight improvement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_IOB = y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                                 all_possible_transitions=True, averaging=None,\n",
       "                                 c=None, c1=None, c2=None,\n",
       "                                 calibration_candidates=None,\n",
       "                                 calibration_eta=None,\n",
       "                                 calibration_max_trials=None,\n",
       "                                 calibration_rate=None,\n",
       "                                 calibration_samples=None, delta=None,\n",
       "                                 epsilon=None, error_sensitive=None,...\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000144959D2898>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['Quality', 'Biotic_Entity', 'Eventuality', 'Location', 'Time', 'Value', 'Aggregate_Biotic_Abiotic_Entity', 'Unit', 'Abiotic_Entity']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [sentence_features(s, step_two=True) for s in train_sentences]\n",
    "y_train = [sentence_labels(s, step_two=True) for s in train_sentences]\n",
    "\n",
    "X_dev = []\n",
    "for ii in range(len(dev_sentences)):\n",
    "    X_dev.append(sentence_features(dev_sentences[ii], step_two=True, predictions=y_predicted_IOB[ii]))\n",
    "y_dev = [sentence_labels(s, step_two=True) for s in dev_sentences]\n",
    "dev_key = [sentence_labels(s) for s in dev_sentences]\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "labels = ['Quality', 'Biotic_Entity', 'Eventuality', 'Location', 'Time', 'Value', 'Aggregate_Biotic_Abiotic_Entity', 'Unit', 'Abiotic_Entity']\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.056551093543686363, 'c2': 0.060760523431746975}\n",
      "best CV score: 0.8462106333597296\n",
      "model size: 1.00M\n"
     ]
    }
   ],
   "source": [
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quality', 'Biotic_Entity', 'Eventuality', 'Location', 'Time', 'Value', 'Aggregate_Biotic_Abiotic_Entity', 'Unit', 'Abiotic_Entity']\n",
      "Class Score: 0.794712740546267\n"
     ]
    }
   ],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.056551093543686363,\n",
    "    c2=0.060760523431746975,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "print(labels)\n",
    "\n",
    "y_predicted = crf.predict(X_dev)\n",
    "\n",
    "f1 = metrics.flat_f1_score(y_dev, y_predicted, average='weighted', labels=labels)\n",
    "print(\"Class Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows no improvement over the values I had before so I won't change them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
